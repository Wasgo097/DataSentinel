# Build stage: compile C++ engine with ONNX Runtime + TensorRT support.
FROM nvidia/cuda:12.6.3-devel-ubuntu24.04 AS builder

ARG ONNXRUNTIME_VERSION=1.24.2
ARG TENSORRT_REPO_DEB=docker/engine/deps/nv-tensorrt-local-repo-ubuntu2404-10.15.1-cuda-12.9_1.0-1_amd64.deb
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /src

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        build-essential \
        cmake \
        libboost-system-dev \
        ca-certificates \
        wget \
        tar \
    && rm -rf /var/lib/apt/lists/*

# Install TensorRT from local NVIDIA repo package present in build context.
COPY ${TENSORRT_REPO_DEB} /tmp/tensorrt-local-repo.deb
RUN dpkg -i /tmp/tensorrt-local-repo.deb \
    && cp /var/nv-tensorrt-local-repo-*/*-keyring.gpg /usr/share/keyrings/ \
    && apt-get update \
    && apt-get install -y --no-install-recommends tensorrt \
    && rm -rf /var/lib/apt/lists/*

# Download prebuilt ONNX Runtime package and unpack to /opt/onnxruntime.
RUN wget -q "https://github.com/microsoft/onnxruntime/releases/download/v${ONNXRUNTIME_VERSION}/onnxruntime-linux-x64-${ONNXRUNTIME_VERSION}.tgz" \
    && tar -xzf "onnxruntime-linux-x64-${ONNXRUNTIME_VERSION}.tgz" \
    && mv "onnxruntime-linux-x64-${ONNXRUNTIME_VERSION}" /opt/onnxruntime \
    && mkdir -p /opt/onnxruntime/lib64 \
    && for f in /opt/onnxruntime/lib/libonnxruntime.so*; do ln -sf "$f" /opt/onnxruntime/lib64/; done \
    && if [ ! -d /opt/onnxruntime/include/onnxruntime ]; then ln -s /opt/onnxruntime/include /opt/onnxruntime/include/onnxruntime; fi

COPY cpp/Engine /src/cpp/Engine
RUN ONNX_CMAKE_DIR="$(find /opt/onnxruntime -type d -path '*/cmake/onnxruntime' | head -n1)" \
    && test -n "$ONNX_CMAKE_DIR" \
    && cmake -S /src/cpp/Engine -B /src/cpp/Engine/build \
        -Donnxruntime_DIR="$ONNX_CMAKE_DIR" \
        -DDS_ENABLE_TENSORRT=ON \
    && cmake --build /src/cpp/Engine/build -j"$(nproc)"

# Runtime stage.
FROM nvidia/cuda:12.6.3-runtime-ubuntu24.04 AS runtime

ARG TENSORRT_REPO_DEB=docker/engine/deps/nv-tensorrt-local-repo-ubuntu2404-10.15.1-cuda-12.9_1.0-1_amd64.deb
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /app

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        libboost-system-dev \
        libstdc++6 \
        ca-certificates \
    && rm -rf /var/lib/apt/lists/*

COPY ${TENSORRT_REPO_DEB} /tmp/tensorrt-local-repo.deb
RUN dpkg -i /tmp/tensorrt-local-repo.deb \
    && cp /var/nv-tensorrt-local-repo-*/*-keyring.gpg /usr/share/keyrings/ \
    && apt-get update \
    && apt-get install -y --no-install-recommends tensorrt \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /opt/onnxruntime /opt/onnxruntime
COPY --from=builder /src/cpp/Engine/build/DataSentinelReceiver /app/DataSentinelReceiver
# Register ONNX Runtime libs in dynamic linker cache instead of overriding
# NVIDIA runtime library paths with a fixed LD_LIBRARY_PATH.
RUN cp /opt/onnxruntime/lib/libonnxruntime.so* /usr/local/lib/ \
    && ldconfig

ENV DATASENTINEL_BACKEND=tensorrt

EXPOSE 9000
CMD ["/app/DataSentinelReceiver"]
